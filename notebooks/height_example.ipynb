{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Fitting VIPRS Model on GWAS data for Standing Height from the UK Biobank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example illustrate how to fit the `VIPRS` model on external GWAS summary statistics \n",
    "from the `fastGWA` catalog. The `fastGWA` catalog is a comprehensive GWAS resource on \n",
    "thousands of phenotypes from the UK Biobank. In this example, we will walk the user \n",
    "through 4 important steps in fitting PRS models to publicly available GWAS summary data:\n",
    "\n",
    "1. **Data pre-processing**: Download the GWAS summary statistics for height and **match** them to genotype data for European samples from the 1000G project. The genotype data is restricted to about 15,000 variants on chromosome 22 for now.\n",
    "\n",
    "2. **Compute LD matrices**: After the GWAS data is downloaded and harmonized with the genotype data, we will compute Linkage-Disequilibrium (LD) matrices that will be used in model fitting. In most applications, it suffices to use publicly available LD matrices, but this example will illustrate how to compute these matrices from genotype data.\n",
    "\n",
    "3. **Model fit**: After the data is preprocessed and we have the LD matrices computed, we will fit the `VIPRS` model to the data. This will result in a set of inferred effect sizes for each of the 15,000 variants.\n",
    "\n",
    "4. **Prediction**: After the model is fit, we will predict (sometimes called scoring or linear scoring) height for the 1000G samples. Unfortunately, we don't have real phenotypes for those samples, so we can't evaluate accuracy, but we can inspect the distribution of polygenic scores, etc.\n",
    "\n",
    "But first things first, let's import the needed packages to run this analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T21:04:15.754890Z",
     "start_time": "2024-04-05T21:04:15.741558Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import magenpy as mgp\n",
    "import viprs as vp\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # ignore warnings"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data pre-processing & harmonization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load and harmonize the data using `magenpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T16:48:56.738961Z",
     "start_time": "2024-04-05T16:47:45.811770Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# GWAS summary statistics for Standing Height from fastGWA:\n",
    "sumstats_url = \"https://yanglab.westlake.edu.cn/data/fastgwa_data/UKB/50.v1.1.fastGWA.gz\"\n",
    "\n",
    "# Load genotype data for European samples in the 1000G project (chromosome 22):\n",
    "gdl = mgp.GWADataLoader(bed_files=mgp.tgp_eur_data_path(),\n",
    "                        sumstats_files=sumstats_url,\n",
    "                        sumstats_format=\"fastGWA\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Computing LD matrices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then, we use `magenpy` to compute the reference LD matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T16:50:06.154841Z",
     "start_time": "2024-04-05T16:49:57.010351Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Compute LD using the shrinkage estimator (Wen and Stephens 2010):\n",
    "gdl.compute_ld(\"shrinkage\",\n",
    "               output_dir=\"~/temp\",  # Output directory where the LD matrix will be stored\n",
    "               genetic_map_ne=11400, # effective population size (Ne)\n",
    "               genetic_map_sample_size=183,\n",
    "               threshold=1e-3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Model fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we fit the `VIPRS` to the harmonized GWAS summary statistics data. Note that the fit will mainly be done on the variants on chromosome 22:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T16:50:16.136153Z",
     "start_time": "2024-04-05T16:50:11.574996Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Fit VIPRS to the summary statistics:\n",
    "v = vp.VIPRS(gdl).fit()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T21:06:25.384444Z",
     "start_time": "2024-04-05T21:06:25.350656Z"
    }
   },
   "source": [
    "To verify that the model fit behaved as expected with no issues, we can inspect \n",
    "the objective (Evidence Lower BOund or `ELBO`) as a function of the number of iterations. `viprs` provides a \n",
    "convenience function to generate this plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T21:06:37.819682Z",
     "start_time": "2024-04-05T21:06:35.161637Z"
    }
   },
   "source": [
    "from viprs.plot.diagnostics import plot_history\n",
    "\n",
    "plot_history(v)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model converged, we can inspect its estimates of both the global hyperparameters as well as summaries of the posterior distribution for the effect sizes of individual variants.\n",
    "\n",
    "To obtain the estimates for some of the global hyperparameters, such as heritability, residual variance, proportion of causal variants, etc., we can simply invoke the method `.to_theta_table`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T21:09:58.696758Z",
     "start_time": "2024-04-05T21:09:58.688218Z"
    }
   },
   "source": [
    "v.to_theta_table()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** `VIPRS` is not a method used to estimate heritability or polygenicity (proportion of causal variants). However, \n",
    "we can obtain estimates for these quantities as part of the model fit.\n",
    "    \n",
    "As for summaries of the posterior distribution, one thing we can look at is the \n",
    "**P**osterior **I**nclusion **P**robability (**PIP**), which is a metric that summarizes \n",
    "the probability that the variant of interest is causal for the phenotype of interest (e.g. Standing Height):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T19:39:29.120032Z",
     "start_time": "2024-04-05T19:39:28.919630Z"
    }
   },
   "source": [
    "# Get the inferred effect sizes:\n",
    "inf_effect_table = v.to_table(col_subset=('CHR', 'SNP', 'POS', 'A1', 'A2'))\n",
    "\n",
    "# Plot the PIP as a function of genomic position:\n",
    "\n",
    "plt.scatter(effect_table['POS'], effect_table['PIP'], \n",
    "            alpha=.4, marker='.')\n",
    "plt.xticks([])\n",
    "plt.xlabel(\"Genomic Position (CHR22)\")\n",
    "plt.ylabel(\"PIP\")\n",
    "plt.title(\"Posterior Inclusion Probability for Standing Height\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T19:41:54.083251Z",
     "start_time": "2024-04-05T19:41:54.076668Z"
    }
   },
   "source": [
    "We see from this that most variants have very small probability of meaningfully contributing to Standing Height. \n",
    "Another illustrative thing that we can do is compare the posterior mean for the effect sizes obtained by `VIPRS` \n",
    "and compare it to the marginal effect sizes obtained from GWAS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T19:40:39.852050Z",
     "start_time": "2024-04-05T19:40:39.623387Z"
    }
   },
   "source": [
    "# Get the summary statistics table:\n",
    "# NOTE: For the purposes of comparing effects on the same scale,\n",
    "# here, we get standardized BETAs, which is why VIPRS uses for inference:\n",
    "sumstats = gdl.to_summary_statistics_table(col_subset=('CHR', 'SNP', 'POS', 'A1', 'A2', 'STD_BETA'))\n",
    "\n",
    "# Rename the BETAs for clarity:\n",
    "sumstats.rename(columns={'STD_BETA': 'GWAS_BETA'}, inplace=True)\n",
    "effect_table.rename(columns={'BETA': 'VIPRS_BETA'}, inplace=True)\n",
    "\n",
    "# Merge the two tables:\n",
    "merged_table = sumstats.merge(effect_table)\n",
    "\n",
    "# Plot the results:\n",
    "plt.scatter(merged_table['GWAS_BETA'], \n",
    "            merged_table['VIPRS_BETA'], \n",
    "            alpha=.5,\n",
    "            marker='.')\n",
    "plt.xlabel(\"Marginal BETA (GWAS)\")\n",
    "plt.ylabel(\"VIPRS Posterior Mean for BETA\")\n",
    "\n",
    "# Plot the unity line to highlight differences in magnitude:\n",
    "x = np.linspace(merged_table[['GWAS_BETA', 'VIPRS_BETA']].min().min(), \n",
    "                merged_table[['GWAS_BETA', 'VIPRS_BETA']].max().max(), 100)\n",
    "plt.plot(x, x, c='red', ls='--')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is a nice illustration of the **selective shrinkage** effect that results \n",
    "from using sparse Bayesian priors, like the **Spike-and-Slab prior** employed by `VIPRS`. Here, the effects \n",
    "for most variants are shrunk towards zero, whereas the few variants that are strongly associated \n",
    "with the phenotype retain their effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T17:05:12.134352Z",
     "start_time": "2024-04-05T17:05:12.075362Z"
    }
   },
   "source": [
    "## 4) Prediction / Generating polygenic scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once convergence is achieved, we are going to predict (i.e. compute polygenic scores) on the European samples in the 1000G data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T17:12:04.390626Z",
     "start_time": "2024-04-05T17:12:04.069105Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Obtain height PGS estimates for the European samples in 1000G Project:\n",
    "height_pgs = v.predict()\n",
    "\n",
    "# plot distribution of height PGS:\n",
    "\n",
    "plt.hist(height_pgs)\n",
    "plt.xlabel(\"Height PGS\")\n",
    "plt.title(\"Height PGS in 1000G (EUR)\")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
